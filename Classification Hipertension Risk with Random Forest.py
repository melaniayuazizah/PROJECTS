# -*- coding: utf-8 -*-
"""HIPERTENSI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KoVHCyDu4uY_asIUFNsWg2nFFh9RTZVq

**KELOMPOK 5 DATA MINING:**

1. Leidaefes Daena R. (24050122120008)
2. Melani Ayu Azizah (24050122120009)
3. Prayuganingtyas Eka S. (24050122120041)
4. Amanda Rizki Koreana (24050122130048)

**TENTANG DATASET**

Dataset ini mencakup atribut demografis dan terkait kesehatan yang bertujuan untuk memprediksi risiko hipertensi. Setiap entri mencakup informasi tentang jenis kelamin, usia, kebiasaan merokok (perokok saat ini dan jumlah rokok per hari), penggunaan obat untuk tekanan darah tinggi (BPMeds), keberadaan diabetes, kadar kolesterol total, tekanan darah sistolik dan diastolik, indeks massa tubuh (BMI), detak jantung, kadar glukosa, dan label risiko hipertensi yang sesuai (0 untuk risiko rendah, 1 untuk risiko tinggi). Dengan total 13 fitur, dataset ini memberikan gambaran menyeluruh tentang faktor-faktor yang berkontribusi pada hipertensi, memfasilitasi pengembangan model prediktif untuk penilaian risiko dan strategi pencegahan.

# Asumsi Objektif

1. Mengidentifikasi faktor-faktor yang mempengaruhi risiko hipertensi pada individu: untuk memahami faktor utama yang berkontribusi terhadap peningkatan risiko hipertensi berdasarkan atribut-atribut demografis, gaya hidup, dan parameter kesehatan
2. Memberikan rekomendasi berbasis bukti untuk intervensi preventif: Berdasarkan hasil analisis, memberikan rekomendasi yang berlandaskan data untuk tindakan preventif yang dapat diterapkan dalam pengelolaan risiko hipertensi, baik di tingkat individu maupun populasi.
3. Membangun model prediktif risiko hipertensi: Menggunakan metode machine learning seperti logistic regression atau random forest untuk mengembangkan model prediktif yang dapat memperkirakan risiko hipertensi pada individu berdasarkan input variabel yang tersedia. Mengevaluasi performa model menggunakan metrik seperti accuracy, precision, recall, dan F1-score.

# Menentukan Objektif

## Menentukan Permasalahan dan Poin - Poin Objektif

- Menentukan Permasalahan

  Diperkirakan 1,28 miliar orang dewasa berusia 30–79 tahun di seluruh dunia menderita hipertensi, dengan sebagian besar (dua pertiga) tinggal di negara-negara berpenghasilan rendah dan menengah. Diperkirakan 46% orang dewasa dengan hipertensi tidak menyadari bahwa mereka memiliki kondisi tersebut. Kurang dari setengah (42%) orang dewasa dengan hipertensi didiagnosis dan mendapatkan pengobatan. Prevalensi Hipertensi akan terus meningkat tajam dan diprediksi pada tahun 2025 sebanyak 29% orang dewasa di seluruh dunia terkena Hipertensi.

- Menentukan Poin-Poin Objektif
  
  Berdasarkan permasalahan yang telah diidentifikasi, poin-poin objektif yang bisa diambil adalah:

1. Mengidentifikasi faktor-faktor utama yang mempengaruhi hipertensi.
2. Memprediksi risiko hipertensi untuk mengambil tindakan preventif.

- Menentukan Metrik Kesuksesan

1. Akurasi model prediksi hipertensi  (misalnya, akurasi lebih dari 80% dalam memprediksi seseorang yang terkena hipertensi).

## Membuat Daftar Terminologi, Sumber Daya, Kebutuhan, Asumsi, dan Batasan

1. Daftar Terminologi
  *   Hypertension: Kondisi medis ketika tekanan darah seseorang secara konsisten lebih tinggi dari batas normal (≥140/90 mmHg).
  *   Systolic Blood Pressure : Tekanan darah yang terjadi ketika jantung memompa darah ke seluruh tubuh.
  *   Diastolic Blood Preassure :  Tekanan darah ketika jantung sedang beristirahat, atau tidak memompa darah.
  *   BMI : Indeks untuk mengetahui apakah seseorang memiliki berat badan yang sehat berdasarkan perbandingan antara berat badan dan tinggi badan.
  *   Predictive Model: Model yang digunakan untuk memprediksi kemungkinan risiko hipertensi.
  *   Accuracy: Metrik yang mengukur seberapa tepat model prediksi dalam mengklasifikasikan seseorang memiliki risiko hipertensi rendah atau tinggi.


2. Sumber Daya
  *   Data: Dataset yang berisi atribut demografis, gaya hidup, dan parameter kesehatan yang bertujuan untuk memprediksi risiko hipertensi.
  *   Alat dan Teknologi:
  *   Python: Untuk analisis data dan pengembangan model prediktif.
  *   Google Colab: Untuk pengolahan dan analisis data.

3. Kebutuhan
  *   Data yang bersih dan lengkap: Pastikan dataset tidak memiliki data yang hilang atau anomali yang signifikan.
  *   Akses ke perangkat lunak yang sesuai: Python dan pustaka pendukung seperti Pandas, Scikit-learn, dsb.
  *   Dukungan institusi kesehatan: Dukungan dari manajemen rumah sakit atau institusi kesehatan untuk implementasi hasil analisis dan strategi pencegahan atau perawatan hipertensi yang diusulkan.

4. Asumsi
  *   Kualitas Data: Asumsinya adalah data yang tersedia sudah cukup representatif untuk menganalisis risiko hipertensi.
  *   Stabilitas Model: Model yang akan dibangun dianggap stabil dan dapat diterapkan dalam skenario dunia nyata.
  *   Dukungan Institusi: Asumsi bahwa institusi kesehatan akan menerima dan mendukung tindakan yang direkomendasikan berdasarkan hasil prediksi.

5. Batasan
  *   Waktu: Batasan waktu untuk menyelesaikan proyek ini adalah sekitar 3 minggu.
  *   Anggaran: Keterbatasan anggaran untuk sumber daya tambahan seperti perangkat lunak, pelatihan, atau akses ke data baru.
  *   Data : Data mungkin terbatas pada rentang waktu tertentu atau jumlah data yang terbatas, sehingga bisa mempengaruhi generalisasi model prediksi.
  *   Kepatuhan Hukum: Harus mematuhi regulasi data kesehatan, seperti HIPAA, GDPR, atau aturan nasional terkait perlindungan data.

## Mengidentifikasi Risiko dan Alternatif Pelaksanaan

1. Identifikasi Risiko

  - Kualitas Data yang Tidak Memadai: Data yang tersedia mungkin memiliki masalah seperti missing values, outliers, atau data yang tidak representatif, yang dapat mempengaruhi hasil analisis dan model prediktif.
  - Overfitting Model: Model yang terlalu kompleks mungkin terlalu fit dengan data pelatihan, sehingga performanya buruk saat diaplikasikan ke data baru.

2. Rencana Mitigasi Risiko
  - Kualitas Data: Lakukan proses pembersihan dan validasi data yang menyeluruh sebelum analisis. Gunakan teknik imputasi untuk mengatasi missing values, dan lakukan normalisasi atau transformasi data jika diperlukan.
  - Overfitting Model: Gunakan teknik seperti cross-validation dan regularization untuk memastikan model tidak overfit. Selain itu, pilih model dengan kompleksitas yang sesuai.

# Menentukan Tujuan Teknis Data Science

Menentukan tujuan teknis yang mendukung objektif yang telah  ditetapkan sebelumnya. Langkah-langkah sebagai berikut :  
1. Menyusun Tujuan Teknis Data Science. Tujuan teknis adalah membangun model prediktif yang dapat mengidentifikasi seseorang beresiko menderita hipertensi. Berikut adalah beberapa tujuan teknis yang ditetapkan :
 *   Mengembangkan Model Prediksi Hipertensi : Menggunakan algoritma machine learning untuk memprediksi apakah seorang beresiko rendah atau tinggi menderita hipertensi, berdasarkan data historis.
 *   Mengoptimalkan Model untuk Akurasi dan Generalisasi: Memastikan model tidak hanya akurat pada data pelatihan tetapi juga mampu memprediksi dengan baik pada data baru.
2. Menentukan Kriteria Kesuksesan Tujuan Teknis

 Setelah menyusun tujuan teknis, langkah selanjutnya adalah menetapkan kriteria kesuksesan yang akan digunakan untuk mengukur keberhasilan proyek ini:
 - Akurasi Model: Model harus mencapai akurasi prediksi minimal 80% untuk dianggap sukses.
 -F1-Score: Menggunakan F1-score sebagai metrik tambahan untuk mengevaluasi performa model secara keseluruhan dalam menyeimbangakan nilai precision dan recall

#Import Data
"""

import pandas as pd
import numpy as np
import missingno as msno
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('/content/Hypertension-risk-model-main.csv')

df.sample(10)

df.rename(columns={'male' : 'sex', 'Risk':'risk'}, inplace=True)

"""Mengganti nama kolom dari male ke sex agar lebih dapat dipahami bahwa kolom tersebut menjelaskan mengenai gender. Mengganti nama kolom Risk menjadi risk agar seragam dengan kolom lain serta phyton sensitif terhadap huruf kapital sehingga dapat mengurangi kesalahan pada saat pengerjaan dikarenakan adanya typo

#Eksplorasi Data
"""

df.info()

"""Berdasarkan hasil eksplorasi awal, berikut adalah tipe data untuk setiap kolom:

Numerik :
*   age : Usia
*   cigsPerDay : Jumlah rokok per hari
*   totChol : Kadar total kolesterol
*   sysBP : Tekanan darah sistolik
*   diaBP : Tekanan darah diastolik
*   BMI : Indeks massa tubuh
*   heartRate : Detak jantung
*   glucose : Kadar glukosa

Kategorik:
*   sex : Jenis kelamin (0 jika laki-laki, 1 jika perempuan)
*   currentSmoker : Status perokok (0 jika tidak, 1 jika iya)
*   BPMeds : Pengguanaan obat tekanan darah tinggi (0 jika tidak, 1 jika iya)
*   diabetes : Status diabetes (0 jika tidak, 1 jika iya)
*   risk : Risiko hipertensi (0 jika risiko rendah, 1 jika risiko tinggi
)

###Pengecekan Proporsi Variabel Target
"""

risk_count = (df['risk'].value_counts(normalize=True)*100).reset_index()

plt.figure(figsize=(8, 6))
sns.barplot(data=risk_count, x='risk', y='proportion',
            palette =['#4682B4','#FF6347'])
plt.xlabel('Risk')
plt.ylabel('Proportion (%)')
plt.title('Proportion of Risk Categories')
plt.show()

print(risk_count)

"""Diatas menunjukan bahwa proporsi variabel target yaitu resiko terkena hipertensi, sebanyak 68,93% beresiko rendah (0) dan sebanyak 31,06% beresiko tinggi(1). Dengan proporsi yang tidak terlalu jauh antara resiko tinggi dan rendah, data ini dapat digunakan untuk membangun model machine learning.

###Eksplorasi Variabel Numerik
"""

plt.figure(figsize=(15, 15), facecolor='white')
plotnumber = 1


cols = ['age', 'cigsPerDay', 'totChol', 'sysBP', 'diaBP',
        'BMI', 'heartRate', 'glucose']


for column in cols:
    ax = plt.subplot(3, 3, plotnumber)
    sns.histplot(data=df, x=column, hue='risk', kde=True, multiple='stack',
                 palette=['#4682B4','#FF6347'])
    plt.xlabel(column, fontsize=10)
    plotnumber += 1

plt.tight_layout()
plt.show()

df[['age', 'cigsPerDay', 'totChol', 'sysBP', 'diaBP',
    'BMI', 'heartRate', 'glucose']].describe()

"""Interpretasi variabel Numerik :   
1.   Age : Variasi umur pada data ada di 32 - 70 tahun. Dengan rata rata umur adalah 49 tahun. Data terdistribusi secara merata. Semakin tinggi umurnya, semakin sedikit jumlah orang yang beresiko rendah terkena hipertensi sedangkan semakin banyak jumlah orang yang beresiko tinggi terkena hipertensi.
2.   Cigs Per Day : Seseorang rata rata merokok 9 batang per hari. Data ini memiliki persebaran yang tidak merata, dengan data berkumpul pada angka 0 serta melonjak di angka 20 batang/hari Nilai minimum adalah 0 batang/hari dan maksimum adalah 70 batang/hari (terindikasi merupakan outlier).
3. Total Cholesterol : Kadar kolesterol rata rata adalah 236 mg/dL dengan kadar terendah 107 mg/dL dan tertinggi 696 mg/dL. Kadar Kolesterol ini distribusinya cukup merata dan melonjak di angka 250 mg/dL. Namun diindikasi memiliki beberapa oulier.
4. Systolic blood pressure : Tekanan darah systolic memiliki rata rata 132 mmHg dengan minimum 83 mmHg dan maksimum 295 mmHg. Tekanan darah ini terdistribusi cukup merata namun memiliki beberapa outlier. Tekanan darah systolic melonjak tinggi pada angka 110, 120 dan 130 mmHg. Seperti dilihat pada bagan, seseorang yang beresiko tinggi terkena hipertensi memiliki tekanan darah systolic terdistribusi di 120 - 200 mmHg.
5. Diastolic blood pressure : Tekanan darah diastolic memiliki rata rata 82
 mmHg dengan minimum 48 mmHg dan maksimum 142 mmHg. Tekanan darah ini terdistribusi cukup merata dibandingkan dengan systolic namun memiliki beberapa outlier yang nilainya tidak terlalu jauh yaitu maksimum 142 mmHg. Seperti dilihat pada bagan, seseorang yang beresiko tinggi terkena hipertensi memiliki tekanan darah diastolic terdistribusi di 70 - 120 mmHg.
6. BMI : Rata rata BMI pada seseorang adalah 25 dengan minimum di angka 15 dan maksimum di angka 56. Distribusi cukup merata walaupun memiliki beberapa outlier. Distribusi antara resiko tinggi dan rendah pun pada angka yang sama. Ada lonjakan kecil di angka 25.
7. Heart Rate : Rata rata Heart rate pada seseorang adalah 75 bpm dengan minimum di angka 44 bpm dan maksimum di angka 143 bpm. Distribusi kurang merata dan memiliki beberapa lonjakan dengan yang paling tinggi disekitar angka 75 bpm. Ada beberapa oulier juga yang terindikasi.
8. Glucose : Rata rata Kadar Glukosa pada seseorang adalah 82 mg/dL dengan minimum di angka 40 mg/dL dan maksimum di angka 394 mg/dL. Distribusi kurang merata dan memiliki lonjakan yang cukup tinggi serta memiliki outlier yang cukup jauh yaitu di 394 mg/dL.

###Eksplorasi Variabel Kategorik
"""

categorical = df[['risk', 'sex', 'currentSmoker', 'BPMeds', 'diabetes']]

fig, axes = plt.subplots(2, 3, figsize=(30, 20))
fig.suptitle('Categorical Data')
row = 0
cols = 0
for item in categorical:
    if (row == 0 & cols == 0) :
        sns.countplot(y=item, hue="risk", data=df, ax=axes[row][cols],
                      palette=['#4682B4','#FF6347']).set_xlabel("")

    else:
        sns.countplot(x=item, hue="risk", data=df, ax=axes[row][cols],
                      palette=['#4682B4','#FF6347']).set_ylabel("")
    cols += 1
    if cols == 3:
        cols = 0
        row += 1

"""Interpretasi terhadap Visualisasi Data Kategorik :

1. Risk : Pada data ini lebih banyak data dengan variabel target resiko rendah terkena hipertensi
2. Sex : Pada data ini lebih banyak laki laki daripada perempuan dengan proporsi yang tidak terlalu jauh
3. Current Smooker : Pada data ini antara yang merokok dan tidak merokok seimbang
4. Blood Presure Meds : Pada data ini lebih banyak orang yang tidak memakai obat obatan untuk menurunkan darah tinggi. Semua orang yang memakai obat obatan ini ternyata beresiko tinggi terkena hipertensi. Ini dapat dijelaskan mungkin sebelumnya mereka sudah tau bahwa mereka terkena hipertensi sehingga digunakanlan obat obatan tersebut
5. Diabetes : Pada data ini lebih banyak seseorang yang tidak mengidap diabetes dengan setengah dari mereka memiliki resiko rendah terkena hipertensi. Orang yang mengidap diabetes memiliki resiko yang sama baik rendah maupun tinggi terkena hipertensi

###Kesimpulan Eksplorasi Data dan Penanganan yang harus dilakukan

Kesimpulan Eksplorasi

Berdasarkan analisis yang telah dilakukan, berikut adalah kesimpulan dari eksplorasi :

- Mengidentifikasi bahwa beberapa variabel seperti umur, tekanan darah sistolik dan tekanan darah diastolik terlihat jelas dalam menggambarkan seseorang yang beresiko tinggi maupun rendah mengalami hipertensi.
-	Beberapa variabel memiliki distribusi yang kurang merata dan memiliki outlier, sehingga akan dilakukan tranformasi dengan feture engineering

# Memvalidasi Data

Pada tahap ini, kita akan memeriksa kelengkapan data dan kualitas data secara keseluruhan. Validasi ini penting untuk memastikan bahwa data siap digunakan untuk analisis lebih lanjut dan pengembangan model prediktif. Langkah-langkah yang akan diambil adalah:

1. Melakukan Pengecekan Kelengkapan Data

	-	Missing Values (Nilai yang Hilang): Memeriksa apakah ada data yang hilang di setiap kolom.
	-	Inconsistencies (Ketidaksesuaian): Memeriksa apakah ada anomali atau data yang tidak konsisten, seperti nilai yang tidak masuk akal untuk fitur tertentu.

2. Membuat Rekomendasi Kelengkapan Data

	-	Berdasarkan hasil pengecekan, kita akan memberikan rekomendasi apakah perlu dilakukan imputasi nilai yang hilang, penghapusan data yang tidak valid, atau perbaikan lainnya.

##Handling Missing Value

Pada tahap ini, kita akan memeriksa kelengkapan data secara keseluruhan. Pemeriksaan kelengkapan data diperlukan untuk memastikan bahwa data siap digunakan untuk analisis lebih lanjut. Pemeriksaan kelengkapan data dilakukan dengan mendeteksi ada atau tidaknya missing values (nilai yang hilang) di setiap kolom (variabel).

Setelah dilakukan pemeriksaan / pengecekan kelengkapan data, selanjutnya kita dapat menentukan tahapan yang perlu dilakukan selanjutnya. Apakah perlu dilakukan imputasi (impute) data yang hilang, ataupun menghapus (drop) variabel yang memiliki missing value.

Penentuan langkah penanganan dipilih berdasarkan ketentuan:
1. IMPUTE (mengganti data yang hilang dengan mean, median, atau modus jika data yang hilang (missing values)) < 25%
2. DROP (menghapus kolom (variabel), jika data yang hilang lebih dari 25%)
"""

msno.matrix(df)

df.isna().sum()

df.isna().mean() * 100

"""Berdasarkan pemeriksaan missing values, ditemukan bahwa terdapat beberapa kolom (variable) yang memiliki missing values, diantaranya:


*   Numerik
    1. cigsPerDay = 29 data hilang dari total 4240 data (0.683962%)
    2. totChol = 50 data hilang dari total 4240 data (1.179245%)
    3. BMI = 19 data hilang dari total 4240 data (0.448113%)
    4. heartRate = 1 data hilang dari total 4240 data (0.023585%)
    5. glucose = 388 data hilang dari total 4240 data (9.150943%)
*   Kategorik
    1. BPMeds = 53 data hilang dari total 4240 data (1.25%)


Dari hasil pemeriksaan, ditemukan 6 variabel (5 variabel numerik dan 1 variabel kategorik) yang memiliki missing values. Sehingga perlu dilakukan penanganan.

Dalam kasus ini, penanganan yang akan kita gunakan yaitu Impute, karena presentase missing value pada keenam variabel < 25%.

Penanganan missing value untuk variabel jenis numerik dan kategorik akan sedikit berbeda. Di mana pada variabel numerik, akan dilakukan pengananan (impute) menggunakan median (tidak menggunakan mean karena distribusi tidak simetris). Sedangkan pada variabel kategorik akan menggunakan modus.



"""

numeric = ['cigsPerDay','totChol','BMI','heartRate','glucose']

df_clean = df.copy()
df_clean[numeric] = df_clean[numeric].fillna(df_clean[numeric].median())

df_clean['BPMeds'] = df['BPMeds'].fillna(df['BPMeds'].mode()[0])

df_clean.sample(10)

msno.matrix(df_clean)

"""Setelah dilakukan penanganan missing value, seluruh kolom atau variabel tidak lagi memiliki missing data, atau dengan kata lain dataset lengkap dan tidak ada lagi data yang hilang.

## CHECKING INCONSISTENCIES
"""

for col in df_clean.columns:
    print(f'{col} : {df[col].unique()}')

"""Berdasarkan hasil pemeriksaan inconsistensies, tidak ditemukan nilai negatif atau nilai tidak wajar dari setiap kolom numerik atau kategorik.

### Rekomendasi Kelengkapan Data
Berdasarkan hasil validasi, pada pemeriksaan missing values ditemukan adanya data missing sehingga dilakukan perbaikan menggunakan impute, dan berhasil ditangani. Kemudian, melalui pemeriksaan inkonsistensi, tidak ditemukan nilai negatif atau nilai tidak wajar dari setiap kolom numerik atau kategorik. Artinya data konsisten untuk digunakan dalam pengembangan model prediktif.

Dari hasil tersebut, dapat disimpulkan bahwa pemeriksaan kelengkapan data dan kualitas data secara keseluruhan, beserta penanganannya telah selesai. Sehingga data siap untuk diperiksa dan divalidasi lebih lanjut.

#Handling Outlier

Berdasarkan hasil validasi sebelumnya, ditemukan adanya missing values pada dataset dan telah berhasil ditangani. Selanjutnya, kita perlu melakukan pemeriksaan akhir terhadap outliers atau nilai-nilai ekstrem yang dapat mempengaruhi hasil analisis untuk memastikan data siap digunakan dalam proses pemodelan.
"""

numerical = df.select_dtypes(include=['int64', 'float64']).columns
len(numerical)

"""Pendeteksian outlier dapat menggunakan IQR Method ataupun Z-score. Secara visualisasi dapat dilihat dengan menggunakan boxplot."""

numerical = df_clean.select_dtypes(include=['int64', 'float64']).columns

fig, axes = plt.subplots(5,3,figsize = (20,10))
fig.subplots_adjust(hspace=1, wspace=0.5)
row = 0
cols = 0

for item in numerical:
    if cols > 2:
        cols = 0
        row += 1
    ax = sns.boxplot(x=item,data=df_clean,ax=axes[row, cols])
    ax.set_ylabel("")
    cols += 1

"""Berdasarkan analisis secara visual dengan metode boxplot dapat terlihat bahwa terdapat outlier pada data 'cigsPerDay', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', dan 'glucose'.

Selanjutnya dilakukan pembersihan data dari outlier dengan menggunakan metode Winsorizing. Metode ini berfungsi untuk membatasi nilai ekstrem (outlier) pada data numerik agar tidak melebihi batas tertentu, dengan cara memotong nilai yang berada di luar lower bound dan upper bound ke batas tersebut, tanpa menghapus data. Implementasi Winsorizing pada data dilakukan dengan memotong outlier menggunakan rumus interquartile range (IQR).
"""

def winsorizing_outlier(df,fitur):
  data_filtered = df.copy()
  for col in num_features:
    data = data_filtered[col]
    q1 = data.quantile(0.25)
    q3 = data.quantile(0.75)
    iqr = q3 - q1
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    data_filtered[col] = data_filtered[col].clip(lower_bound,upper_bound)

  return data_filtered

num_features = ['cigsPerDay','totChol','sysBP',
                'diaBP','BMI','heartRate','glucose']
df_tmp = winsorizing_outlier(df_clean,num_features)

"""Dilakukan pendeteksian outlier kembali secara viusal dengan menggunakan boxplot."""

numerical = df_tmp.select_dtypes(include=['int64', 'float64']).columns

fig, axes = plt.subplots(5,3,figsize = (20,10))
fig.subplots_adjust(hspace=1, wspace=0.5)
row = 0
cols = 0

for item in numerical:
    if cols > 2:
        cols = 0
        row += 1
    ax = sns.boxplot(x=item,data=df_tmp ,ax=axes[row, cols])
    ax.set_ylabel("")
    cols += 1

"""Setelah dilakukan pembersihan outlier dengan Winsorizing, berdasarkan analisis secara visual dengan metode boxplot dapat terlihat bahwa sudah tidak terdapat lagi outlier pada data 'cigsPerDay', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', dan 'glucose'. Hal ini menunjukkan bahwa distribusi data telah berada dalam batas yang wajar dan tidak lagi memiliki nilai ekstrem yang dapat mengganggu analisis.

#Feature Engineering

### Transformasi Data

-	Pada data Numerik, beberapa variabel memiliki distribusi yang tidak merata sehingga perlu dilakukan transformasi data seperti Standard Scaler, Yeo Jeonson, maupun Robust dan dipilih satu transformasi data dengan distribusi data paling normal
- Untuk data Kategorik tidak perlu dilakukan transformasi karena sudah dalam bentuk numerik
"""

import matplotlib.pyplot as plt
import seaborn as sns
# plot histogram of numerical variables
df_tmp.hist(bins=50, figsize=(15,10))
plt.show();

num = ['cigsPerDay','totChol','sysBP','diaBP','BMI','heartRate','glucose']

"""##STANDARD

"""

from sklearn.preprocessing import StandardScaler
df_standard= df_tmp.copy()

scaler = StandardScaler()
df_standard[num] = scaler.fit_transform(df_tmp[num])

df_standard[num].hist(figsize = (15,8))
print(df_standard[num].describe())

"""- Fitur-fitur numerik dilakukan standarisasi agar memiliki skala yang seragam dan meningkatkan performa model.
- Fitur tersebut dinormalisasi agar memiliki nilai rata-rata 0 dan standar deviasi 1.

##YEO J
"""

df_yeo = df_tmp.copy()

from sklearn.preprocessing import PowerTransformer

scaler = PowerTransformer(method = "yeo-johnson")
df_yeo[num] = scaler.fit_transform(df_tmp[num])

df_yeo[num].hist(figsize = (15,8))
print(df_yeo[num].describe())

"""##ROBUST"""

df_robust = df_tmp.copy()

from sklearn.preprocessing import RobustScaler

scaler = RobustScaler()
df_robust[num] = scaler.fit_transform(df_tmp[num])

df_robust[num].hist(figsize = (15,8))
print(df_robust[num].describe())

df_end = df_standard.copy()

"""Berdasarkan hasil transformasi data, transformasi menggunakan Standard Scaler memiliki distribusi data yang paling baik sehingga transformasi data yang dipilih adalah Standard Scaler

#Membuat Skenario Model

## Mengidentifikasi Teknik Pemodelan

Berdasarkan karakteristik data dan tujuan prediksi resiko hipertensi, berikut adalah beberapa algoritma yang dapat digunakan :

- Logistic Regression : Algoritma sederhana dan mudah diintepretasikan yang dapat digunakan untuk klasifikasi biner seperti pada dataset ini yaitu ‘resiko rendah’ dan ‘resiko tinggi’.
- K-Nearest Neighbors(KNN) : Algoritma ini mudah untuk dipahami dan dijelaskan serta tidak perlu memenuhi asumsi apapun.
- Random Forest : Algoritma ini baik digunakan pada dataset yang tidak seimbang seperti pada dataset ini yaitu 68% data resiko rendah dan 32% data resiko tinggi
- Extra Gradient Boosting (XGBoost) : Algoritma ini cocok untuk data yang kompleks dan memiliki banyak feature (variabel) dan efektif untuk meningkatkan akurasi prediksi pada data yang kompleks.

## Mengidentifikasi Teknik Pemodelan yang Sesuai

Memulai dengan model yang sederhana yaitu Logistic Regression bila hasilnya kurang memuaskan dapat menggunakan model lain yang lebih kompleks yaitu KNN, Random Forest maupun XGBoost.

## Evaluasi Model

Metrik evaluasi yang dapat digunakan untuk mengukur performa model meliputi:

-	Accuracy: Seberapa sering model memberikan prediksi yang benar.
-	Precision : Kemampuan model untuk mengidentifikasi semua resiko dari beberapa kelas.
-	Recall : Kemampuan model untuk menangkap kesalahan negatif dari keselurahn kelas dari resiko.
-   F1-Score (macro) : Mengukur keseimbangan antara precision dan Recall.
- Confusion Matrix : Memberikan gambaran jelas tentang seberapa baik model memprediksi kelas yang benar dibandingkan dengan kelas yang salah.

## Target Evaluasi Model

Komponen Confusion Matrix :
1. True Positives (TP): Jumlah kasus resiko rendah dan diprediksi sebagai resiko rendah oleh model. Ini adalah prediksi yang benar untuk kelas resiko rendah.

2. True Negatives (TN): Jumlah kasus resiko tinggi dan diprediksi sebagai resiko tinggi oleh model. Ini adalah prediksi yang benar untuk kelas resiko tinggi.

3. False Positives (FP): Jumlah kasus yang sebenarnya resiko rendah tetapi diprediksi sebagai resiko tinggi oleh model. Ini disebut juga sebagai kesalahan tipe II.

4. False Negatives (FN): Jumlah kasus yang sebenarnya resiko tinggi tetapi diprediksi sebagai resiko rendah oleh model. Ini disebut juga sebagai kesalahan tipe II.

Pada model ini, akan dicari model yang meminimumkan False Negatives (FN) daripada FP dikarenakan lebih baik seseorang didiagnosa beresiko tinggi terkena hipertensi padahal aslinya beresiko rendah. Dibandingkan seseorang didiagnosa beresiko rendah padahal aslinya beresiko tinggi. Bila FN ini besar, maka akan fatal akibatnya bagi seseorang yang didiagnosa karena tidak dapat diberikan penanganan yang cepat.

Sehingga untuk evaluasi model, kita dapat memperhatikan :    
1. Confusion Matrix, pada map dipilih FN terkecil yaitu pada Prediksi (0) & Sebenarnya (1)
2. Akurasi yang tinggi dibandingkan model lain
3. Recall yang tinggi daripada model lain
4. Precision yang tinggi daripada model lain
5. F1- Score yang tinggi dibandingkan model lain

#Modeling

## Membagi data menjadi train & test
"""

from sklearn.model_selection import train_test_split

X = df_end.drop(columns = ['risk'])
y = df_end['risk']

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.25,
                                                 random_state = 42)
print(X_train.shape)
print(X_test.shape)

"""## Model Regresi Logistik"""

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(X_train,y_train)

from sklearn.metrics import classification_report

y_pred = lr.predict(X_test)
print(classification_report(y_test,y_pred, digits = 5))

"""##KNN"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier()
knn.fit(X_train,y_train)

from sklearn.metrics import classification_report

y_pred = knn.predict(X_test)
print(classification_report(y_test,y_pred, digits = 5))

"""##Random Forest"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()
rf.fit(X_train,y_train)

from sklearn.metrics import classification_report

y_pred = rf.predict(X_test)
print(classification_report(y_pred, y_test, digits = 5))

"""##XGBoost"""

from xgboost import XGBClassifier

xgb = XGBClassifier(random_state = 42)
xgb.fit(X_train, y_train)

from sklearn.metrics import classification_report
y_pred = xgb.predict(X_test)
print(classification_report(y_test, y_pred, digits = 5))

"""## Hasil Evaluasi Model

Hasil evaluasi sebagai berikut :    
1. Akurasi tertinggi pada model XGBoost sebesar 90,189%. Disusul Random Forest dan Linear Regression sebesar 89,906%
2. Recall tertinggi pada model XGBoost sebesar 88,897%. Disusul Random Forest sebesar 87,322%
3. Precision tertinggi pada model Random Forest sebesar 89,521%
4. F-1 Score tertinggi pada model XGBoost sebesar 88,402%. Disusul Random Forest sebesar 88,278%

Dapat terlihat bahwa 3 dari 4 parameter evaluasi paling baik ada pada model XGBoost, tetapi karena tujuan model ini adalah meminimumkan False Negative (FN) maka perlu dilakukan evaluasi menggunakan confusion matrix

##Confusion Matrix
"""

from sklearn.metrics import confusion_matrix

models = {
    'Logistic Regression': LogisticRegression(),
    'KNN': KNeighborsClassifier(),
    'Random Forest': RandomForestClassifier(),
    'XGBoost': XGBClassifier(random_state=42)
}

# Buat subplots untuk menampilkan heatmap
fig, axes = plt.subplots(2, 2, figsize=(8, 6))
axes = axes.flatten()

for ax, (model_name, model) in zip(axes, models.items()):
    # Latih model
    model.fit(X_train, y_train)

    # Prediksi
    y_pred = model.predict(X_test)

    # Hitung confusion matrix
    cm = confusion_matrix(y_test, y_pred)

    # Buat heatmap
    sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap='Reds')
    ax.set_title(model_name)
    ax.set_xlabel('Prediksi')
    ax.set_ylabel('Sebenarnya')

# Menampilkan plot
plt.tight_layout()
plt.show()

"""Nilai False Negative (FN) terkecil ada pada model Random Forest yaitu sebanyak 37 orang.

# Model Terbaik

Model yang terpilih adalah model dengan FN terkecil, dilanjutkan dengan akurasi, recall, precision dan f1-score terbaik.

Model terbaik adalah **Random Forest** dengan :    
1. Nilai FN sebanyak 38 orang
2. Akurasi sebesar 89,906%
2. Recall sebesar 87,322%
3. Precision sebesar 89,521%
4. F-1 Score sebesar 88,278%

Nilai akurasi sudah lebih dari kriteria kesuksesan model yaitu 80%
"""